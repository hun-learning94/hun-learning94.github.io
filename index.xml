<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hun Learning</title>
    <link>/</link>
    <description>Recent content on Hun Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Aug 2020 11:00:00 +0900</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Note on Kullback-Leibler Divergence</title>
      <link>/posts/bayesian-ml/week5/04-note-on-kullback-leibler-divergence/</link>
      <pubDate>Mon, 10 Aug 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week5/04-note-on-kullback-leibler-divergence/</guid>
      <description>How do we quantify an amount of information that some data $x$ contains? If the data is pretty much expected than it tells nothing new to us. But if it is so rare then it has some value. In this sense, we can think of an amount of information as a &amp;ldquo;degree of surprise&amp;rdquo;, and define
$$ \text{information content of data $x$:}\quad h(x) = -\log p(x) $$ where the logarithm ensures $h(x,y)=h(x)+h(y) \Leftrightarrow p(x,y)=p(x)p(y)$, and the negative sign makes $h(x)\geq 0$.</description>
    </item>
    
    <item>
      <title>EM Algorithm for Latent Variable Models</title>
      <link>/posts/bayesian-ml/week5/03-em-algorithm-for-latent-variable-models/</link>
      <pubDate>Mon, 10 Aug 2020 10:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week5/03-em-algorithm-for-latent-variable-models/</guid>
      <description>For an observed data $\mathbf{x}$, we might posit the existence of an unobserved data $\mathbf{z}$ and include it in model $p(\mathbf{x,z}\mid \theta)$. This is called a latent variable model. The question is, why bother? It turns out that in many cases, learning $\theta$ with the marginal log likelihood $p(\mathbf{x}\mid \theta)$ is hard, whereas learning with the joint likelihood with a complete data set $p(\mathbf{x,z}\mid \theta)$ is relatively easy. GMM is one such case.</description>
    </item>
    
    <item>
      <title>Mixtures of Gaussians and EM algorithm</title>
      <link>/posts/bayesian-ml/week5/02-mixtures-of-gaussians-and-em/</link>
      <pubDate>Mon, 10 Aug 2020 07:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week5/02-mixtures-of-gaussians-and-em/</guid>
      <description>Mixtures of Gaussians (GMM) GMM as a joint distribution Suppose a random vector $\mathbf{x}$ follows a $K$ Gaussian mixture distribution,
$$ p(\mathbf{x}) = \sum_{k=1}^K \pi_k N(\mathbf{x}\mid \boldsymbol{\mu_k, \Sigma_k}) $$ Knowing the distribution means we have complete information about the set of parameters $\pi_k, \boldsymbol{\mu_k, \Sigma_k}$ for all $k$. Let us say that the parameter $\pi_k$ is shrouded, and instead we have a random variable $\mathbf{z}$ with $1-to-K$ coding where exactly one of $K$ elements (say $z_k$) be $1$ while all else are $0$.</description>
    </item>
    
    <item>
      <title>K-means clustering</title>
      <link>/posts/bayesian-ml/week5/01-k-means-clustering/</link>
      <pubDate>Mon, 10 Aug 2020 06:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week5/01-k-means-clustering/</guid>
      <description>Gaussian mixture model is a widely used probabilistic model. For inference (model learning), we may use either EM algorithm which is a MLE approach or use Bayesian approach, which leads to variational inference. We would study this topic next week. For now, let us introduce one of the well-known nonparameteric methods for unsupervised learning, and introduce Gaussian mixture as a parametric counterpart.
K-means clustering Let us suppose that we know the total number of clusters is fixed as $K$.</description>
    </item>
    
    <item>
      <title>Bayesian Hierarchical Modeling and its Applications</title>
      <link>/posts/bayesian-ml/week3/03-bayesian-hierarchical-modeling-and-applications/</link>
      <pubDate>Mon, 03 Aug 2020 08:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week3/03-bayesian-hierarchical-modeling-and-applications/</guid>
      <description>Review: Full conditional posterior for normal likelihood 일단 정규분포의 semi-conjugate prior에 대한 내용을 다시 정리해보자.
 $p(\theta\mid\sigma^2, \mathbf{D}) = dnorm(\theta, \mu_n, \tau_n^2)$ $\mu_n= \dfrac{1/\tau_0^2}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}\mu_0 + \dfrac{\frac{n}{\sigma^2}}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}\bar{x}$ $\tau_n^2 = \dfrac{1}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}$ $p(\sigma^2\mid\theta, \mathbf{D}) = dinv\Gamma(\sigma^2, v_n, \dfrac{1}{v_n}(v_0\sigma_0^2+\sum (y_i-\theta)^2)$  Two Group Comparison: Math scores library(ggplot2) library(cowplot) school1 = dget(&amp;#39;http://www2.stat.duke.edu/~pdh10/FCBS/Inline/y.school1&amp;#39;) school2 = dget(&amp;#39;http://www2.stat.duke.edu/~pdh10/FCBS/Inline/y.school2&amp;#39;) df = data.frame(school = c(rep(&amp;#39;s1&amp;#39;, length(school1)),rep(&amp;#39;s2&amp;#39;, length(school2))), score = c(school1, school2) ) ggplot(df, aes(x=school, y=score))+ geom_boxplot(aes(fill=school))+ ggtitle(&amp;#39;Math scores comparison&amp;#39;)+ theme_cowplot() 통계학이 필요한 이유는 이런 &amp;ldquo;애매한&amp;rdquo; 차이 때문이다.</description>
    </item>
    
    <item>
      <title>(MCMC) 베이지안 사후분포 근사를 위한 MCMC 방법론</title>
      <link>/posts/bayesian-ml/week3/02-mcmc-approximation-for-bayesian-posterior/</link>
      <pubDate>Mon, 03 Aug 2020 07:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week3/02-mcmc-approximation-for-bayesian-posterior/</guid>
      <description>0. 개요 베이지안에서 모수에 대한 추론은 곧 모수의 분포를 구하는 것이다. 미지의 수에 대한 불확실성을 확률로 표현하였으니, 베이즈 정리를 이용해 데이터의 불확실성과 거짓말처럼 깔끔하게 같이 섞을 수 있기 때문이다. 그러나 아쉽게도 그 결과로 나오는 분포는 항상 깔끔하지만은 않다. 물론 데이터에 대한 모델을 지수분포족으로 한정하고, 그에 대응하는 또다른 특별한 지수분포족 분포함수를 사용하면, 사후분포의 모수를 쉽게 구할 수 있는데, 이러한 경우를 Prior-Posterior 간에 Conjugacy가 있다고 한다. 그러나 많은 경우 복잡한 데이터에 맞게 모델을 만들다 보면 해석적이지 않은 사후분포에 맞닥뜨리게 된다.</description>
    </item>
    
    <item>
      <title>(MCMC) Discrete-Time Markov Chain with Finite State Space</title>
      <link>/posts/bayesian-ml/week3/01-discrete-time-markov-chaine-with-finite-state-space/</link>
      <pubDate>Mon, 03 Aug 2020 06:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week3/01-discrete-time-markov-chaine-with-finite-state-space/</guid>
      <description>0. 이걸 왜 배우는데? 저번 시간에 간략히 살펴본 Gibbs Sampler는 MCMC(Markov Chain Monte Carlo), 즉 마코브 체인을 이용한 Posterior 분포 시뮬레이션 방법 중 하나인데, 이 MCMC 방법들이 도대체가 왜 잘 먹히는 지를 알려면 아무래도 마코브 체인에 대한 배경지식이 필요하다. 어떤 분포를 MCMC로 근사한다는 것은 모수 공간의 어떤 포인트에서 다른 포인트로 총총 점프하는 그 과정을 &amp;ldquo;잘&amp;rdquo; 구현해서, 마치 그 샘플들이 내가 모르는 그 분포에서 나온 것과 같다고 퉁치는 거다.
MCMC 이름의 의미</description>
    </item>
    
    <item>
      <title>Conjugate Prior for Multivariate Model</title>
      <link>/posts/bayesian-ml/week2/03-conjugate-prior-for-multivariate-model/</link>
      <pubDate>Mon, 20 Jul 2020 06:10:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week2/03-conjugate-prior-for-multivariate-model/</guid>
      <description>library(ggplot2) library(cowplot) library(reshape) Multivariate Normal Model Consider a bivariate normal random variable $[y_1, y_2]^T$. The density is written as ($p=2$)
$$ p(\mathbf{y}|\theta, \Sigma) = (\dfrac{1}{2\pi})^{-p/2}|\Sigma|^{-1/2} \exp{-\dfrac{1}{2}(\mathbf{y}-\theta)^T\Sigma^{-1}(\mathbf{y}-\theta)} $$
where the parameter is $\theta = \begin{pmatrix} E[y_1]\\\ E[y_2] \end{pmatrix}$ and $\Sigma = \begin{pmatrix} E[y_1^2]-E[y_1]^2 &amp;amp; E[y_1y_2]-E[y_1]E[y_2]\\\
E[y_2y_1]-E[y_2]E[y_1] &amp;amp; E[y_2^2]-E[y_2]^2 \end{pmatrix}$ $=\begin{pmatrix} \sigma_1^2 &amp;amp; \sigma_{12}\\\
\sigma_{21} &amp;amp; \sigma_2^1 \end{pmatrix}$.
Few things worth mentioning for multivariate normal model
  the term in the exponent $(\mathbf{y}-\theta)^T\Sigma^{-1}(\mathbf{y}-\theta)$ is somewhat a measure of distance between mean and the data.</description>
    </item>
    
    <item>
      <title>Conjugate Prior for Univariate - Normal Model</title>
      <link>/posts/bayesian-ml/week2/02-conjugate-prior-for-univariate-normal-model/</link>
      <pubDate>Mon, 20 Jul 2020 06:05:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week2/02-conjugate-prior-for-univariate-normal-model/</guid>
      <description>Inference for Normal Model Normal likelihood model has two parameters
$$ p(x|\theta, \sigma^2) = \dfrac{1}{\sigma\sqrt{2\pi}}\exp(-\dfrac{1}{2}(\dfrac{x-\theta}{\sigma})^2) $$ which requires a joint prior $p(\theta, \sigma^2)$. As for a single parameter case, we have joint posterior updated as
$$ p(\theta, \sigma^2|\mathbf{D}) \propto p(\theta, \sigma^2)p(\mathbf{D}|\theta, \sigma^2) $$ When our interest is in $\theta$, $\sigma^2$ is a nuisance parameter. Given the data $\mathbf{D}$ and the normal likelihood, we have three ways to deal with $\sigma^2$;</description>
    </item>
    
    <item>
      <title>Conjugate Prior for Univariate - Poisson Model</title>
      <link>/posts/bayesian-ml/week2/01-conjugate-prior-univariate-poisson/</link>
      <pubDate>Mon, 20 Jul 2020 06:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week2/01-conjugate-prior-univariate-poisson/</guid>
      <description>library(ggplot2) library(cowplot) library(reshape) Bayesian Update and Prediction Given a data $\mathbf{D}={x_1, x_2, &amp;hellip;, x_n}$, once a likelihood model $p(\mathbf{D}|\theta)$ and a prior on a parameter $p(\theta)$ are specified, Bayesian inference produces an updated belief on $\theta$.
$$ \begin{align} \text{Prior Belief}&amp;amp;\quad p(\theta)\\\
\text{Likelihood}&amp;amp;\quad p(\mathbf{D}|\theta)\\\
\text{Updated (Posterior)}&amp;amp;\quad p(\theta|\mathbf{D}) = \dfrac{p(\mathbf{D}|\theta)p(\theta)}{\int p(\mathbf{D}|\theta)p(\theta)d\theta} \propto p(\mathbf{D}|\theta)p(\theta) \end{align} $$
Our interest may extend to the prediction the new value $\tilde{x}$ that would be generated from the same sampling distribution.</description>
    </item>
    
    <item>
      <title>Bayesian Approach: 하나의 데이터, 임의의 모수</title>
      <link>/posts/bayesian-ml/week1/08-bayesian-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%AA%A8%EC%88%98/</link>
      <pubDate>Mon, 20 Jul 2020 05:30:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/08-bayesian-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%AA%A8%EC%88%98/</guid>
      <description>0. 생각하는 로봇은 베이지안이다! 주변 환경을 인지하고 목적지를 찾는 로봇을 생각해보자. 목적지로 가는 경로에는 수많은 경우의 수가 있다. 이 경로에서 로봇은 시시각각 환경을 파악해서, 즉 데이터를 수집해서 가장 안전한 길을 택해야 한다. 전방에 위험징후를 포착했다. 로봇은 그 방향으로 가는 길이 위험하다고 판단해 경로를 변경해야 한다. 자 그러면 이걸 어떻게 코딩할까? 각각의 길이 위험할 확률 $p(road_i=unsafe)$과, 각각의 길에서 위험한 징후가 포착될 확률 $p(sign\mid road_i=unsafe)$ 을 고려하여, 위험할 확률 $p(road_i = unsafe \mid sign)$ 을 다시 계산해야한다.</description>
    </item>
    
    <item>
      <title>07 빈도론적 귀무가설유의수준검정(NHST)의 문제점</title>
      <link>/posts/bayesian-ml/week1/07-%EB%B9%88%EB%8F%84%EB%A1%A0%EC%A0%81-%EA%B7%80%EB%AC%B4%EA%B0%80%EC%84%A4%EC%9C%A0%EC%9D%98%EC%88%98%EC%A4%80%EA%B2%80%EC%A0%95nhst%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90/</link>
      <pubDate>Mon, 20 Jul 2020 05:20:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/07-%EB%B9%88%EB%8F%84%EB%A1%A0%EC%A0%81-%EA%B7%80%EB%AC%B4%EA%B0%80%EC%84%A4%EC%9C%A0%EC%9D%98%EC%88%98%EC%A4%80%EA%B2%80%EC%A0%95nhst%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90/</guid>
      <description>1. 빈도론적 추론의 병폐 자 이제 빈도통계론의 논리도 이해했고 그 끝판왕인 MLE와 LRT도 봤습니다. 지금부터는 빈도론적 통계 추론, 그 중에서도 검정 (NHST)이 가진 &amp;ldquo;병폐&amp;quot;들에 대해서 살펴보겠습니다. 앞서 잠깐 봤는데, 여기서는 좀 더 자세하게 다뤄보겠습니다.
1) Trigger Happy: $p(D \mid H_0)$만 보고 $H_0$을 기각함 $p(D\mid H_0)$이 굉장히 작아야지만 귀무가설을 기각하는 것이 얼핏 보면 굉장히 보수적으로 보이지만, 사실 이런 식으로 세팅을 해놓으면 &amp;ldquo;귀무가설에 반대되는 evidence&amp;quot;만 반영하게 되지, 귀무가설에 좋은 evidence는 절대 반영을 못함.</description>
    </item>
    
    <item>
      <title>06 Maximum Likelihood Theory</title>
      <link>/posts/bayesian-ml/week1/06-maximum-likelihood-theory/</link>
      <pubDate>Mon, 20 Jul 2020 05:10:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/06-maximum-likelihood-theory/</guid>
      <description>지금까지의 논의를 종합해보면 다음과 같습니다.
  빈도통계학 추론은 평행우주 데이터 ${D^{(s)}}_{s=1}^{\infty}$에서의 Sampling Distrubtion $\delta(D^{(s)}) \sim p(.\mid \theta^*)$에 달렸다.
  모수 $\theta$에 대한 추정량 $\hat{\theta} = \delta(D^{(s)})$의 결정은 다음의 사항을 고려해야 한다.
  일단 $\delta$의 sampling distribtion을 근사적으로나마 알아야 한다.
  가급적이면 $\delta$의 평행우주 데이터 ${D^{(s)}}_{s=1}^{\infty}$에서의 행태가 &amp;ldquo;이쁘면&amp;rdquo; 좋겠다. (Consistent, Unbiased, Efficient)
    Sampling distribution $\delta(D^{(s)}) \sim p(.\mid\theta^*)$만 알면 점 추정, 구간 추정, 가설 검정 다 할 수 있다!</description>
    </item>
    
    <item>
      <title>05 Frequentist Optimality: 어떤 추정량을 쓸 것인가?</title>
      <link>/posts/bayesian-ml/week1/05-frequentist-optimality-%EC%96%B4%EB%96%A4-%EC%B6%94%EC%A0%95%EB%9F%89%EC%9D%84-%EC%93%B8-%EA%B2%83%EC%9D%B8%EA%B0%80/</link>
      <pubDate>Mon, 20 Jul 2020 05:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/05-frequentist-optimality-%EC%96%B4%EB%96%A4-%EC%B6%94%EC%A0%95%EB%9F%89%EC%9D%84-%EC%93%B8-%EA%B2%83%EC%9D%B8%EA%B0%80/</guid>
      <description>빈도론자들의 세계관을 다시 한번 복기해봅시다. 데이터의 sampling density를 모수 $\theta$로 결정되는 확률분포함수로 가정하였고, $\theta$를 모를 때 이 sampling density를 데이터에 의해 정해지는 $\theta$의 식인 Likelihood로 해석합니다. 비록 우리가 가진 샘플은 $D^{(s)}$ 하나이지만 내가 모르는 수많은 평행우주에 똑같은 확률실험의 결과들의 앙상블인 ${D^{(s)}}_{s=1}^{\infty}$가 있다고 믿어봅시다.
$$ \begin{align} \text{Ensemble of Data:}\quad &amp;amp; D_{s=1}^{\infty} = [x_1^{(s)}, x_2^{(s)}, &amp;hellip;, x_n^{(s)}]_{s=1}^{\infty}\\\
\text{Sampling Density of $D^{(s)}$ (iid):}\quad&amp;amp; f(D^{(s)}|\theta) = \prod_{i=1}^nf(x_i^{(s)}|\theta) \quad (x_i^{(s)}\in \mathcal{X}, \theta \in \Omega)\\\
\text{Likelihood of $\theta$ given $D^{(s)}$:}\quad&amp;amp; L(\theta|D^{(s)}) \end{align} $$ 우리는 데이터를 보고 모수를 추정하고자 합니다.</description>
    </item>
    
    <item>
      <title>04 Frequentist Approach 하나의 모수, 여러 개의 데이터</title>
      <link>/posts/bayesian-ml/week1/04-frequentist-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%AA%A8%EC%88%98-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0/</link>
      <pubDate>Mon, 20 Jul 2020 04:50:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/04-frequentist-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%AA%A8%EC%88%98-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0/</guid>
      <description>이제 대략적인 소개는 했으니 수식을 사용해 좀 더 자세히 설명해볼게요. 일단 데이터 형성 과정에 대한 우리의 가정을 Likelihood로 표현해봅시다.
$$ \begin{align} \text{Data (iid):}\quad &amp;amp;D = [x_1, x_2, &amp;hellip;, x_n]\\\
\text{Sampling Density of $D$:}\quad&amp;amp; f(D|\theta) = \prod_{i=1}^nf(x_i|\theta) \quad (x_i\in \mathcal{X}, \theta \in \Omega)\\\
\text{Likelihood of $\theta$:}\quad&amp;amp; L(\theta|D) \end{align} $$
1. 빈도론적 세계관 이해하기 위의 가정은 빈도론과 베이즈 접근법에 상관없이 일반적으로 데이터의 형성과정을 확률 모델로 가정함과 동시에 성립하는 그냥 자명한 사실들입니다. 그러나 빈도론적 세계관에서는 이를 다음과 같이 다시 씁니다.</description>
    </item>
    
    <item>
      <title>03 빈도통계학과 베이즈통계학: 철학의 차이</title>
      <link>/posts/bayesian-ml/week1/03-%EB%B9%88%EB%8F%84%ED%86%B5%EA%B3%84%ED%95%99%EA%B3%BC-%EB%B2%A0%EC%9D%B4%EC%A6%88%ED%86%B5%EA%B3%84%ED%95%99-%EC%B2%A0%ED%95%99%EC%9D%98-%EC%B0%A8%EC%9D%B4/</link>
      <pubDate>Mon, 20 Jul 2020 04:40:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/03-%EB%B9%88%EB%8F%84%ED%86%B5%EA%B3%84%ED%95%99%EA%B3%BC-%EB%B2%A0%EC%9D%B4%EC%A6%88%ED%86%B5%EA%B3%84%ED%95%99-%EC%B2%A0%ED%95%99%EC%9D%98-%EC%B0%A8%EC%9D%B4/</guid>
      <description>이제부터는 inference와 prediction 문제를 해결하는 통계학의 두 가지 접근법을 차례로 살펴보겠습니다. 첫 번째는 빈도통계학 접근법으로, 학부 통계학에서 가장 많이 접해본 내용입니다. 사실 그냥 통입 통방 수통1 수통2가 전부다 빈도통계학을 위한 준비 + 논리 이해하기입니다. 그래서 베이즈통계 안 듣고 졸업하면 통계학을 반쪽만 알고 가는거에요. 두 번째는 베이지안 접근법인데, 두 방법의 큰 차이점은 모수에 대한 해석의 차이라고 생각해요. 빈도통계학 접근법에서 추론이란 알지는 못하지만 단 하나의 상수로 존재하는 참 모수 $\theta$ 찾기에요. 우리는 한 번 확률 실험으로 얻은 데이터를 가지고 모수를 찾아야하는 참 안습한 상황에 처해있지요.</description>
    </item>
    
    <item>
      <title>02 통계학의 목적: Inference와 Prediction</title>
      <link>/posts/bayesian-ml/week1/02-%ED%86%B5%EA%B3%84%ED%95%99%EC%9D%98-%EB%AA%A9%EC%A0%81-inference%EC%99%80-prediction/</link>
      <pubDate>Mon, 20 Jul 2020 04:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/02-%ED%86%B5%EA%B3%84%ED%95%99%EC%9D%98-%EB%AA%A9%EC%A0%81-inference%EC%99%80-prediction/</guid>
      <description>이처럼 데이터는 알고 모수는 모르는 상황에서, 우리는 오직 하나의 Likelihood 함수만 관측할 수 있습니다. 이 Likelihood 함수를 가지고 통계학자들이 하고 싶은 일은 두 가지로 요약할 수 있습니다.
 Inference: 데이터 $\mathbf{x}$를 바탕으로 모수 $\theta$에 대해 무엇을 말할 수 있는가? Prediction: 데이터 $\mathbf{x}$를 바탕으로 새로운 데이터 $x_{new}$를 예측해보자.  동전의 예를 생각해보면, inference는 이 동전이 과연 fair한가 아닌가, 즉 앞면이 나올 확률이 무엇인가에 대해 답하고자 하는 것이며, prediction은 그렇다면 다음 시행에서 앞면이 나올지 뒷면이 나올지 예측하는 것입니다.</description>
    </item>
    
    <item>
      <title>01 Probability Densities와 Likelihood</title>
      <link>/posts/bayesian-ml/week1/01-probability-densities%EC%99%80-likelihood/</link>
      <pubDate>Mon, 20 Jul 2020 03:43:58 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/01-probability-densities%EC%99%80-likelihood/</guid>
      <description>어떤 확률 변수 $x_i$가 가질 수 있는 값들을 sample space $\mathcal{X}$라고 하고, 그 값들의 분포는 어떤 모수 $\theta$에 의해 완전히 결정되는 함수 $f(x\mid\theta)$라고 생각해봅시다(예컨대 이항분포나 분산이 주어진 정규분포 등을 생각해볼 수 있겠습니다). 모수 $\theta$가 가질 수 있는 값들은 parameter space $\mathcal{\Omega}$라고 합니다. (이때 모수 $\theta$는 스칼라가 아니라 벡터일 수도 있습니다. 여기서는 스칼라인 경우만 일단 생각해볼게요.)
$$ \text{Sampling Density of $x_i$:}\quad f(x|\theta) \quad (x\in \mathcal{X}, \theta \in \Omega) $$
이때 함수 $f$를 probability density라고 합니다.</description>
    </item>
    
    <item>
      <title>Author</title>
      <link>/posts/about/</link>
      <pubDate>Sat, 11 Jul 2020 09:10:00 +0900</pubDate>
      
      <guid>/posts/about/</guid>
      <description>“Study hard what interests you the most in the most undisciplined, irreverent and original manner possible.” (Richard Feynmann)
 About My name is Kang Gyeonghun (Korean: 강경훈, Pronunciation: Khane-gi-yeong-hoon). I am currently an undergraduate student in Yonsei University, Korea. I am majoring in Economics but I was disenchanted with that subject way back, and had dreamed of being an professional investor. I spent most of my eight semesters of undergraduate course studying corporate finance, accounting, portfolio strategy and such, along with an internship in a local private equity.</description>
    </item>
    
    <item>
      <title>Logit Regression과 SVM은 Loss function의 차이</title>
      <link>/posts/2020-06-15-logit-svm/</link>
      <pubDate>Mon, 15 Jun 2020 09:10:00 +0900</pubDate>
      
      <guid>/posts/2020-06-15-logit-svm/</guid>
      <description>학교 과제로 썼던 자료인데 조금 다듬어서 블로그에 올립니다.
I. Intro 2범주 범주형자료분석에서 여러 개의 연속형 응답변수가 주어졌을 때 쓸 수 있는 확률 모형의 대표적인 예는 로지스틱 회귀가 있다. 모델의 계수에 대한 해석이 가능한 Generalized Linear Model의 틀 안에 있기 때문에 결과에 대한 해석이 가능한 장점이 있다. 로지스틱 회귀는 로그 오드에 대한 선형식으로 Likelihood를 세워 MLE 방식으로 추정하는 함수적 추정 방법이다. 그러나 범주형자료분석에서 만일 목적이 예측이라면 해석이 불가능한 비모수적 함수 추정 방법을 쓸 수 있는데, 그 대표적인 예가 옆 동네 컴퓨터 공학과에서 처음 개발한 Support Vector Machine 방법이다.</description>
    </item>
    
    <item>
      <title>Support Vector Machine 이해를 위한 Lagrangian Dual Problem 이해해보기</title>
      <link>/posts/2020-04-17-support-vector-machine-%EC%9D%B4%ED%95%B4%EB%A5%BC-%EC%9C%84%ED%95%9C-lagrangian-dual-problem/</link>
      <pubDate>Fri, 17 Apr 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-04-17-support-vector-machine-%EC%9D%B4%ED%95%B4%EB%A5%BC-%EC%9C%84%ED%95%9C-lagrangian-dual-problem/</guid>
      <description>Optimization with inequality constraints 다음과 같은 최적화 문제를 생각해보자.
$$ \begin{align*} \textbf{Primal Problem:}\quad minimize &amp;amp;\quad f_0(\mathbf{x}) \quad (\mathbf{x} \in \mathbb{R}^n, ;domain;\mathcal{D})\\\
s.t. &amp;amp;\quad f_i(\mathbf{x}) \leq 0, \quad ^\forall i \in [m] \\\
&amp;amp;\quad h_i(\mathbf{x})=0 \quad ^\forall i \in [p] \end{align*} $$
우리가 익숙한 Lagrange Multiplier에서는 제약식이 등호로만 되어있었지만, 이제는 부등식이 추가되었다. 이러한 경우 부등호 조건식 $f_i(\mathbf{x})$를 inequality constraints, 등호 조건식 $h_i(\mathbf{x})$를 equality constraints라고 한다.
부등호 조건이 들어간 최적화 문제를 푸는 것은 참 막막한 일이다.</description>
    </item>
    
    <item>
      <title>Classification을 위한 선형 방법들</title>
      <link>/posts/linear-methods-for-classification/</link>
      <pubDate>Fri, 10 Apr 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/linear-methods-for-classification/</guid>
      <description>1. Classification and Test Error Rate 데이터 $x_i$에 대해 target 변수 $t_i$가 범주형 자료인 경우 (남자/여자, 성공/실패, 양념/간장/후라이드) 우리가 세우는 예측 모델 $f$을 Classifier라고 한다.
$$ Classifier:; \hat{t_i} = f(x_i)$$
당연히 우리의 모델 $f$는 종종 틀릴 것이다. Regression에서는 우리가 Error를 예측값과 실제값 사이의 거리의 제곱을 오차로 정의했다면, Classification은 좀 더 간단하게 전체 데이터에서 틀리게 분류된 횟수로 Error를 정의한다. 자세히 말하자면 아래와 같은 Indicator function을 만들어놓고
$$ Classification;Error:; I(t_i \neq \hat{t_i}) = \begin{cases} 0 &amp;amp; \text{if } t_i = \hat{t_i} \\\</description>
    </item>
    
    <item>
      <title>Ridge와 Lasso, 그리고 베이지안 해석</title>
      <link>/posts/2020-04-07-ridge%EC%99%80-lasso-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%ED%95%B4%EC%84%9D/</link>
      <pubDate>Tue, 07 Apr 2020 12:00:00 +0900</pubDate>
      
      <guid>/posts/2020-04-07-ridge%EC%99%80-lasso-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%ED%95%B4%EC%84%9D/</guid>
      <description>References  Pattern Recognition and Machine Learning, Bishop, 2006 Introduction to Statistical Learning, James et al, 2013  </description>
    </item>
    
    <item>
      <title>Test MSE 분해하기: Bias-Variance Tradeoff</title>
      <link>/posts/2020-04-07-test-mse/</link>
      <pubDate>Tue, 07 Apr 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-04-07-test-mse/</guid>
      <description>References Pattern Recognition and Machine Learning, Bishop, 2006</description>
    </item>
    
    <item>
      <title>03 Matrix Derivatives</title>
      <link>/posts/2020-03-29-03-matrix-derivatives/</link>
      <pubDate>Sun, 29 Mar 2020 09:20:00 +0900</pubDate>
      
      <guid>/posts/2020-03-29-03-matrix-derivatives/</guid>
      <description>훈러닝 채널에 벡터 및 행렬 미분 강의 있습니다!</description>
    </item>
    
    <item>
      <title>02 Example: Change of Variables</title>
      <link>/posts/2020-03-29-02-example-change-of-variables/</link>
      <pubDate>Sun, 29 Mar 2020 09:10:00 +0900</pubDate>
      
      <guid>/posts/2020-03-29-02-example-change-of-variables/</guid>
      <description>훈러닝 채널에 벡터 및 행렬 미분 강의 있습니다!</description>
    </item>
    
    <item>
      <title>01 Vector Derivatives</title>
      <link>/posts/2020-03-29-01-vector-derivatives/</link>
      <pubDate>Sun, 29 Mar 2020 09:00:00 +0900</pubDate>
      
      <guid>/posts/2020-03-29-01-vector-derivatives/</guid>
      <description>훈러닝 채널에 벡터 및 행렬 미분 강의 있습니다!</description>
    </item>
    
    <item>
      <title>04 Least Squares Projection</title>
      <link>/posts/2020-03-25-04-least-squares-projection/</link>
      <pubDate>Wed, 25 Mar 2020 09:50:00 +0900</pubDate>
      
      <guid>/posts/2020-03-25-04-least-squares-projection/</guid>
      <description>훈러닝 채널에 선형대수 강의 있습니다!</description>
    </item>
    
    <item>
      <title>03 Matrix as a Change of Basis</title>
      <link>/posts/2020-03-25-03-matrix-as-a-change-of-basis/</link>
      <pubDate>Wed, 25 Mar 2020 09:40:00 +0900</pubDate>
      
      <guid>/posts/2020-03-25-03-matrix-as-a-change-of-basis/</guid>
      <description>훈러닝 채널에 선형대수 강의 있습니다!</description>
    </item>
    
    <item>
      <title>02 Matrix as a Linear Operator</title>
      <link>/posts/2020-03-25-02-matrix-as-a-linear-operator/</link>
      <pubDate>Wed, 25 Mar 2020 09:30:00 +0900</pubDate>
      
      <guid>/posts/2020-03-25-02-matrix-as-a-linear-operator/</guid>
      <description>훈러닝 채널에 선형대수 강의 있습니다!</description>
    </item>
    
    <item>
      <title>01 Length, Angle and Area</title>
      <link>/posts/2020-03-25-01-length-angle-and-area/</link>
      <pubDate>Wed, 25 Mar 2020 09:00:00 +0900</pubDate>
      
      <guid>/posts/2020-03-25-01-length-angle-and-area/</guid>
      <description>훈러닝 채널에 선형대수 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 09 Support Vector Machine</title>
      <link>/posts/2020-01-26-isl-09-support-vector-machine/</link>
      <pubDate>Sun, 26 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-26-isl-09-support-vector-machine/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 08 Tree Based Methods and Boosting</title>
      <link>/posts/2020-01-25-isl-08-tree-based-methods-and-boosting/</link>
      <pubDate>Sat, 25 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-25-isl-08-tree-based-methods-and-boosting/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 07 Nonlinear Regression</title>
      <link>/posts/2020-01-24-isl-07-nonlinear-regression/</link>
      <pubDate>Fri, 24 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-24-isl-07-nonlinear-regression/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 06 Model Selection and Regularization</title>
      <link>/posts/2020-01-23-isl-06-model-selection-and-regularization/</link>
      <pubDate>Thu, 23 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-23-isl-06-model-selection-and-regularization/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 05 Resampling Methods</title>
      <link>/posts/2020-01-22-isl-05-resampling-methods/</link>
      <pubDate>Wed, 22 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-22-isl-05-resampling-methods/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 04 Classification</title>
      <link>/posts/2020-01-21-isl-04-classification/</link>
      <pubDate>Tue, 21 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-21-isl-04-classification/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
    <item>
      <title>ISL 02 Statistical Learning</title>
      <link>/posts/2020-01-20-isl-02-statistical-learning/</link>
      <pubDate>Mon, 20 Jan 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/2020-01-20-isl-02-statistical-learning/</guid>
      <description>훈러닝 채널에 ISL 전 범위 유투브 강의 있습니다!</description>
    </item>
    
  </channel>
</rss>