<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Hun Learning</title>
    <link>/categories/statistics/</link>
    <description>Recent content in Statistics on Hun Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jul 2020 05:20:00 +0900</lastBuildDate>
    
	<atom:link href="/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>07 빈도론적 귀무가설유의수준검정(NHST)의 문제점</title>
      <link>/posts/bayesian-ml/week1/07-%EB%B9%88%EB%8F%84%EB%A1%A0%EC%A0%81-%EA%B7%80%EB%AC%B4%EA%B0%80%EC%84%A4%EC%9C%A0%EC%9D%98%EC%88%98%EC%A4%80%EA%B2%80%EC%A0%95nhst%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90/</link>
      <pubDate>Mon, 20 Jul 2020 05:20:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/07-%EB%B9%88%EB%8F%84%EB%A1%A0%EC%A0%81-%EA%B7%80%EB%AC%B4%EA%B0%80%EC%84%A4%EC%9C%A0%EC%9D%98%EC%88%98%EC%A4%80%EA%B2%80%EC%A0%95nhst%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90/</guid>
      <description>1. 빈도론적 추론의 병폐 자 이제 빈도통계론의 논리도 이해했고 그 끝판왕인 MLE와 LRT도 봤습니다. 지금부터는 빈도론적 통계 추론, 그 중에서도 검정 (NHST)이 가진 &amp;ldquo;병폐&amp;quot;들에 대해서 살펴보겠습니다. 앞서 잠깐 봤는데, 여기서는 좀 더 자세하게 다뤄보겠습니다.
1) Trigger Happy: $p(D \mid H_0)$만 보고 $H_0$을 기각함 $p(D\mid H_0)$이 굉장히 작아야지만 귀무가설을 기각하는 것이 얼핏 보면 굉장히 보수적으로 보이지만, 사실 이런 식으로 세팅을 해놓으면 &amp;ldquo;귀무가설에 반대되는 evidence&amp;quot;만 반영하게 되지, 귀무가설에 좋은 evidence는 절대 반영을 못함.</description>
    </item>
    
    <item>
      <title>06 Maximum Likelihood Theory</title>
      <link>/posts/bayesian-ml/week1/06-maximum-likelihood-theory/</link>
      <pubDate>Mon, 20 Jul 2020 05:10:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/06-maximum-likelihood-theory/</guid>
      <description>지금까지의 논의를 종합해보면 다음과 같습니다.
  빈도통계학 추론은 평행우주 데이터 ${D^{(s)}}_{s=1}^{\infty}$에서의 Sampling Distrubtion $\delta(D^{(s)}) \sim p(.\mid \theta^*)$에 달렸다.
  모수 $\theta$에 대한 추정량 $\hat{\theta} = \delta(D^{(s)})$의 결정은 다음의 사항을 고려해야 한다.
  일단 $\delta$의 sampling distribtion을 근사적으로나마 알아야 한다.
  가급적이면 $\delta$의 평행우주 데이터 ${D^{(s)}}_{s=1}^{\infty}$에서의 행태가 &amp;ldquo;이쁘면&amp;rdquo; 좋겠다. (Consistent, Unbiased, Efficient)
    Sampling distribution $\delta(D^{(s)}) \sim p(.\mid\theta^*)$만 알면 점 추정, 구간 추정, 가설 검정 다 할 수 있다!</description>
    </item>
    
    <item>
      <title>05 Frequentist Optimality: 어떤 추정량을 쓸 것인가?</title>
      <link>/posts/bayesian-ml/week1/05-frequentist-optimality-%EC%96%B4%EB%96%A4-%EC%B6%94%EC%A0%95%EB%9F%89%EC%9D%84-%EC%93%B8-%EA%B2%83%EC%9D%B8%EA%B0%80/</link>
      <pubDate>Mon, 20 Jul 2020 05:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/05-frequentist-optimality-%EC%96%B4%EB%96%A4-%EC%B6%94%EC%A0%95%EB%9F%89%EC%9D%84-%EC%93%B8-%EA%B2%83%EC%9D%B8%EA%B0%80/</guid>
      <description>빈도론자들의 세계관을 다시 한번 복기해봅시다. 데이터의 sampling density를 모수 $\theta$로 결정되는 확률분포함수로 가정하였고, $\theta$를 모를 때 이 sampling density를 데이터에 의해 정해지는 $\theta$의 식인 Likelihood로 해석합니다. 비록 우리가 가진 샘플은 $D^{(s)}$ 하나이지만 내가 모르는 수많은 평행우주에 똑같은 확률실험의 결과들의 앙상블인 ${D^{(s)}}_{s=1}^{\infty}$가 있다고 믿어봅시다.
$$ \begin{align} \text{Ensemble of Data:}\quad &amp;amp; D_{s=1}^{\infty} = [x_1^{(s)}, x_2^{(s)}, &amp;hellip;, x_n^{(s)}]_{s=1}^{\infty}\\\
\text{Sampling Density of $D^{(s)}$ (iid):}\quad&amp;amp; f(D^{(s)}|\theta) = \prod_{i=1}^nf(x_i^{(s)}|\theta) \quad (x_i^{(s)}\in \mathcal{X}, \theta \in \Omega)\\\
\text{Likelihood of $\theta$ given $D^{(s)}$:}\quad&amp;amp; L(\theta|D^{(s)}) \end{align} $$ 우리는 데이터를 보고 모수를 추정하고자 합니다.</description>
    </item>
    
    <item>
      <title>04 Frequentist Approach 하나의 모수, 여러 개의 데이터</title>
      <link>/posts/bayesian-ml/week1/04-frequentist-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%AA%A8%EC%88%98-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0/</link>
      <pubDate>Mon, 20 Jul 2020 04:50:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/04-frequentist-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%AA%A8%EC%88%98-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0/</guid>
      <description>이제 대략적인 소개는 했으니 수식을 사용해 좀 더 자세히 설명해볼게요. 일단 데이터 형성 과정에 대한 우리의 가정을 Likelihood로 표현해봅시다.
$$ \begin{align} \text{Data (iid):}\quad &amp;amp;D = [x_1, x_2, &amp;hellip;, x_n]\\\
\text{Sampling Density of $D$:}\quad&amp;amp; f(D|\theta) = \prod_{i=1}^nf(x_i|\theta) \quad (x_i\in \mathcal{X}, \theta \in \Omega)\\\
\text{Likelihood of $\theta$:}\quad&amp;amp; L(\theta|D) \end{align} $$
1. 빈도론적 세계관 이해하기 위의 가정은 빈도론과 베이즈 접근법에 상관없이 일반적으로 데이터의 형성과정을 확률 모델로 가정함과 동시에 성립하는 그냥 자명한 사실들입니다. 그러나 빈도론적 세계관에서는 이를 다음과 같이 다시 씁니다.</description>
    </item>
    
    <item>
      <title>03 빈도통계학과 베이즈통계학: 철학의 차이</title>
      <link>/posts/bayesian-ml/week1/03-%EB%B9%88%EB%8F%84%ED%86%B5%EA%B3%84%ED%95%99%EA%B3%BC-%EB%B2%A0%EC%9D%B4%EC%A6%88%ED%86%B5%EA%B3%84%ED%95%99-%EC%B2%A0%ED%95%99%EC%9D%98-%EC%B0%A8%EC%9D%B4/</link>
      <pubDate>Mon, 20 Jul 2020 04:40:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/03-%EB%B9%88%EB%8F%84%ED%86%B5%EA%B3%84%ED%95%99%EA%B3%BC-%EB%B2%A0%EC%9D%B4%EC%A6%88%ED%86%B5%EA%B3%84%ED%95%99-%EC%B2%A0%ED%95%99%EC%9D%98-%EC%B0%A8%EC%9D%B4/</guid>
      <description>이제부터는 inference와 prediction 문제를 해결하는 통계학의 두 가지 접근법을 차례로 살펴보겠습니다. 첫 번째는 빈도통계학 접근법으로, 학부 통계학에서 가장 많이 접해본 내용입니다. 사실 그냥 통입 통방 수통1 수통2가 전부다 빈도통계학을 위한 준비 + 논리 이해하기입니다. 그래서 베이즈통계 안 듣고 졸업하면 통계학을 반쪽만 알고 가는거에요. 두 번째는 베이지안 접근법인데, 두 방법의 큰 차이점은 모수에 대한 해석의 차이라고 생각해요. 빈도통계학 접근법에서 추론이란 알지는 못하지만 단 하나의 상수로 존재하는 참 모수 $\theta$ 찾기에요. 우리는 한 번 확률 실험으로 얻은 데이터를 가지고 모수를 찾아야하는 참 안습한 상황에 처해있지요.</description>
    </item>
    
    <item>
      <title>02 통계학의 목적: Inference와 Prediction</title>
      <link>/posts/bayesian-ml/week1/02-%ED%86%B5%EA%B3%84%ED%95%99%EC%9D%98-%EB%AA%A9%EC%A0%81-inference%EC%99%80-prediction/</link>
      <pubDate>Mon, 20 Jul 2020 04:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/02-%ED%86%B5%EA%B3%84%ED%95%99%EC%9D%98-%EB%AA%A9%EC%A0%81-inference%EC%99%80-prediction/</guid>
      <description>이처럼 데이터는 알고 모수는 모르는 상황에서, 우리는 오직 하나의 Likelihood 함수만 관측할 수 있습니다. 이 Likelihood 함수를 가지고 통계학자들이 하고 싶은 일은 두 가지로 요약할 수 있습니다.
 Inference: 데이터 $\mathbf{x}$를 바탕으로 모수 $\theta$에 대해 무엇을 말할 수 있는가? Prediction: 데이터 $\mathbf{x}$를 바탕으로 새로운 데이터 $x_{new}$를 예측해보자.  동전의 예를 생각해보면, inference는 이 동전이 과연 fair한가 아닌가, 즉 앞면이 나올 확률이 무엇인가에 대해 답하고자 하는 것이며, prediction은 그렇다면 다음 시행에서 앞면이 나올지 뒷면이 나올지 예측하는 것입니다.</description>
    </item>
    
    <item>
      <title>01 Probability Densities와 Likelihood</title>
      <link>/posts/bayesian-ml/week1/01-probability-densities%EC%99%80-likelihood/</link>
      <pubDate>Mon, 20 Jul 2020 03:43:58 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week1/01-probability-densities%EC%99%80-likelihood/</guid>
      <description>어떤 확률 변수 $x_i$가 가질 수 있는 값들을 sample space $\mathcal{X}$라고 하고, 그 값들의 분포는 어떤 모수 $\theta$에 의해 완전히 결정되는 함수 $f(x\mid\theta)$라고 생각해봅시다(예컨대 이항분포나 분산이 주어진 정규분포 등을 생각해볼 수 있겠습니다). 모수 $\theta$가 가질 수 있는 값들은 parameter space $\mathcal{\Omega}$라고 합니다. (이때 모수 $\theta$는 스칼라가 아니라 벡터일 수도 있습니다. 여기서는 스칼라인 경우만 일단 생각해볼게요.)
$$ \text{Sampling Density of $x_i$:}\quad f(x|\theta) \quad (x\in \mathcal{X}, \theta \in \Omega) $$
이때 함수 $f$를 probability density라고 합니다.</description>
    </item>
    
    <item>
      <title>Logit Regression과 SVM은 Loss function의 차이</title>
      <link>/posts/2020-06-15-logit-svm/</link>
      <pubDate>Mon, 15 Jun 2020 09:10:00 +0900</pubDate>
      
      <guid>/posts/2020-06-15-logit-svm/</guid>
      <description>학교 과제로 썼던 자료인데 조금 다듬어서 블로그에 올립니다.
I. Intro 2범주 범주형자료분석에서 여러 개의 연속형 응답변수가 주어졌을 때 쓸 수 있는 확률 모형의 대표적인 예는 로지스틱 회귀가 있다. 모델의 계수에 대한 해석이 가능한 Generalized Linear Model의 틀 안에 있기 때문에 결과에 대한 해석이 가능한 장점이 있다. 로지스틱 회귀는 로그 오드에 대한 선형식으로 Likelihood를 세워 MLE 방식으로 추정하는 함수적 추정 방법이다. 그러나 범주형자료분석에서 만일 목적이 예측이라면 해석이 불가능한 비모수적 함수 추정 방법을 쓸 수 있는데, 그 대표적인 예가 옆 동네 컴퓨터 공학과에서 처음 개발한 Support Vector Machine 방법이다.</description>
    </item>
    
    <item>
      <title>Classification을 위한 선형 방법들</title>
      <link>/posts/linear-methods-for-classification/</link>
      <pubDate>Fri, 10 Apr 2020 11:00:00 +0900</pubDate>
      
      <guid>/posts/linear-methods-for-classification/</guid>
      <description>1. Classification and Test Error Rate 데이터 $x_i$에 대해 target 변수 $t_i$가 범주형 자료인 경우 (남자/여자, 성공/실패, 양념/간장/후라이드) 우리가 세우는 예측 모델 $f$을 Classifier라고 한다.
$$ Classifier:; \hat{t_i} = f(x_i)$$
당연히 우리의 모델 $f$는 종종 틀릴 것이다. Regression에서는 우리가 Error를 예측값과 실제값 사이의 거리의 제곱을 오차로 정의했다면, Classification은 좀 더 간단하게 전체 데이터에서 틀리게 분류된 횟수로 Error를 정의한다. 자세히 말하자면 아래와 같은 Indicator function을 만들어놓고
$$ Classification;Error:; I(t_i \neq \hat{t_i}) = \begin{cases} 0 &amp;amp; \text{if } t_i = \hat{t_i} \\\</description>
    </item>
    
  </channel>
</rss>