<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posterior Approximation on Hun Learning</title>
    <link>/tags/posterior-approximation/</link>
    <description>Recent content in Posterior Approximation on Hun Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Aug 2020 10:00:00 +0900</lastBuildDate>
    
	<atom:link href="/tags/posterior-approximation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Variational Inference and Bayesian Gaussian Mixture Model</title>
      <link>/posts/2020-08-25-variational-inference/</link>
      <pubDate>Tue, 25 Aug 2020 10:00:00 +0900</pubDate>
      
      <guid>/posts/2020-08-25-variational-inference/</guid>
      <description></description>
    </item>
    
    <item>
      <title>(MCMC) 베이지안 사후분포 근사를 위한 MCMC 방법론</title>
      <link>/posts/bayesian-ml/week3/02-mcmc-approximation-for-bayesian-posterior/</link>
      <pubDate>Mon, 03 Aug 2020 07:00:00 +0900</pubDate>
      
      <guid>/posts/bayesian-ml/week3/02-mcmc-approximation-for-bayesian-posterior/</guid>
      <description>0. 개요 베이지안에서 모수에 대한 추론은 곧 모수의 분포를 구하는 것이다. 미지의 수에 대한 불확실성을 확률로 표현하였으니, 베이즈 정리를 이용해 데이터의 불확실성과 거짓말처럼 깔끔하게 같이 섞을 수 있기 때문이다. 그러나 아쉽게도 그 결과로 나오는 분포는 항상 깔끔하지만은 않다. 물론 데이터에 대한 모델을 지수분포족으로 한정하고, 그에 대응하는 또다른 특별한 지수분포족 분포함수를 사용하면, 사후분포의 모수를 쉽게 구할 수 있는데, 이러한 경우를 Prior-Posterior 간에 Conjugacy가 있다고 한다. 그러나 많은 경우 복잡한 데이터에 맞게 모델을 만들다 보면 해석적이지 않은 사후분포에 맞닥뜨리게 된다.</description>
    </item>
    
    <item>
      <title>Bayesian Modelling by Zoubin Ghahramani, MLSS2012, Univ of Cambridge</title>
      <link>/posts/2020-07-31-bayesian-modeling/</link>
      <pubDate>Fri, 31 Jul 2020 09:10:00 +0900</pubDate>
      
      <guid>/posts/2020-07-31-bayesian-modeling/</guid>
      <description>베이지안 머신러닝에 대해 인터넷에서 자료를 찾다보니 꽤 괜찮은 동영상 강의가 있어서 요약해보았다. 베이지안 모델링에 대해 개괄적으로 설명해주는 강의인데, 머신러닝에서 베이즈 정리가 어떻게 쓰이는지 잘 설명된 자료인 것 같다.
http://videolectures.net/mlss2012_ghahramani_bayesian_modelling/
위 링크에서 해당 강의 자료를 다운받고 시청할 수 있다. 다만 어도비 플래시가 있어야 구동이 되니 아마 올해가 지나면 못 듣지 않을까 싶다. 베이지안 모델링 외에도 Bayesian Nonparametrics, Graphical Model 등등 다른 다양한 강의가 있으니 한번 참고해보자.
아래에다가 강의 슬라이드별로 강의에서 아저씨가 말씀하신 부분을 나름 보충을 섞어 요약해놨다.</description>
    </item>
    
  </channel>
</rss>