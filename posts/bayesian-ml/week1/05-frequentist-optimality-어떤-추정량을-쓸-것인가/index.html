<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>05 Frequentist Optimality: 어떤 추정량을 쓸 것인가? - Hun Learning</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="Example article description">
		<meta property="og:title" content="05 Frequentist Optimality: 어떤 추정량을 쓸 것인가?" />
<meta property="og:description" content="Example article description" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bayesian-ml/week1/05-frequentist-optimality-%EC%96%B4%EB%96%A4-%EC%B6%94%EC%A0%95%EB%9F%89%EC%9D%84-%EC%93%B8-%EA%B2%83%EC%9D%B8%EA%B0%80/" />
<meta property="article:published_time" content="2020-07-20T05:00:00+09:00" />
<meta property="article:modified_time" content="2020-07-20T05:00:00+09:00" />

		<meta itemprop="name" content="05 Frequentist Optimality: 어떤 추정량을 쓸 것인가?">
<meta itemprop="description" content="Example article description">
<meta itemprop="datePublished" content="2020-07-20T05:00:00+09:00" />
<meta itemprop="dateModified" content="2020-07-20T05:00:00+09:00" />
<meta itemprop="wordCount" content="611">



<meta itemprop="keywords" content="Statistics,Probability,Frequentist," />

	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed">
		<a class="logo__link" href="/" title="Hun Learning" rel="home">
			<div class="logo__item logo__imagebox">
					<img class="logo__img" src="/mypic2.jpg">
				</div><div class="logo__item logo__text">
					<div class="logo__title">Hun Learning</div>
					<div class="logo__tagline">In Search Of The Truth Projected Onto A Finite Dimension</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/posts/about/">
				
				<span class="menu__text">Author</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
	<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
</script>
<script type="text/javascript" async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "all" } }
  });
</script>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">05 Frequentist Optimality: 어떤 추정량을 쓸 것인가?</h1>
			<p class="post__lead">가장 좋은 추정량 같은 것은 없다.</p>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">Kang Gyeonghun</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2020-07-20T05:00:00&#43;09:00">2020-07-20</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/statistics/" rel="category">Statistics</a>
	</span>
</div></div>
		</header>
		<figure class="post__thumbnail">
			<img src="/cover/classical.jpg" alt="05 Frequentist Optimality: 어떤 추정량을 쓸 것인가?">
		</figure>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#brreferences"><!-- raw HTML omitted -->References</a></li>
  </ul>
</nav>
	</div>
</div>
<div class="content post__content clearfix">
			<p><!-- raw HTML omitted --><!-- raw HTML omitted -->빈도론자들의 세계관을 다시 한번 복기해봅시다. 데이터의 sampling density를 모수 $\theta$로 결정되는 확률분포함수로 가정하였고, $\theta$를 모를 때 이 sampling density를 데이터에 의해 정해지는 $\theta$의 식인 Likelihood로 해석합니다. 비록 우리가 가진 샘플은 $D^{(s)}$ 하나이지만 내가 모르는 수많은 평행우주에 똑같은 확률실험의 결과들의 앙상블인 ${D^{(s)}}_{s=1}^{\infty}$가 있다고 믿어봅시다.</p>
<!-- raw HTML omitted -->
<p>$$
\begin{align}
\text{Ensemble of Data:}\quad &amp; D_{s=1}^{\infty} = [x_1^{(s)}, x_2^{(s)}, &hellip;, x_n^{(s)}]_{s=1}^{\infty}\\\<br>
\text{Sampling Density of $D^{(s)}$ (iid):}\quad&amp; f(D^{(s)}|\theta) = \prod_{i=1}^nf(x_i^{(s)}|\theta) \quad (x_i^{(s)}\in \mathcal{X}, \theta \in \Omega)\\\<br>
\text{Likelihood of $\theta$ given $D^{(s)}$:}\quad&amp; L(\theta|D^{(s)})
\end{align}
$$
<!-- raw HTML omitted -->우리는 데이터를 보고 모수를 추정하고자 합니다. 앞서 배운 빈도론적 방식을 다시 쓰면 다음과 같습니다.</p>
<!-- raw HTML omitted -->
<p>$$
\begin{align}
\text{True (fixed) Parameter:}&amp; \quad \theta^*\\\<br>
\text{Estimator of $\theta^*$ given $D^{(s)}$:} &amp;\quad \delta(D^{(s)})= \hat{\theta}(D^{(s)})\\\<br>
\text{(Limiting) Sampling Distribution of $\delta(D^{(s)})$:}&amp;\quad  \delta(D^{(s)}) \sim p(.|\theta^*)
\end{align}
$$
<!-- raw HTML omitted -->앞서 살펴본 예시는 관심 모수가 모평균이고 추정량이 표본평균인 경우였습니다. 중심극한정리 덕분에 모수를 몰라도 추정량의 극한분포, 즉 asymptotic sampling distribution을 알 수 있었고, 덕분에 모수에 대한 점 추정치와 신뢰구간을 제시할 수 있었으며, 모수가 귀무가설의 영역에 있을 때의 추정량의 극한분포 (즉 검정통계량의 극한분포)를 사용해 나름의 가설 검정도 할 수 있었습니다.</p>
<p><!-- raw HTML omitted -->그런데 왜 표본평균으로 했는지에 대한 설명은 따로 하지 않았습니다. 즉 $\delta(D^{(s)})$의 선택에 대한 이야기를 하지 않았습니다. 자 여러분이 $\delta(D^{(s)})$를 선택해야하는 빈도통계학자라고 생각해봅시다. 관찰은 못 하는데 분명 우주 어딘가에 존재하는 데이터들이 ${D^{(s)}}_{s=1}^{\infty}$이 있습니다. 각각의 데이터에서 추정량 $\delta$의 선택에 따라 하나의 모수에 대한 각기 다른 추정치를 얻겠죠. 그렇다면 나는 $\delta(D^{(s)})$를 결정할 때, 모든 데이터에 대해서 계산한 &ldquo;오차&quot;를 최대한 줄이는 방향으로 하고 싶습니다. 이때 **각각의 데이터에서 계산한 오차를 &ldquo;Loss&quot;라고 하며, 모든 데이터에 대해서 이 Loss를 계산하여 평균을 내린 값을 &ldquo;Risk&quot;라고 합니다. **Loss는 어떻게 정의하기 나름인데, 여기서는 예시로 squared loss를 쓰겠습니다.</p>
<!-- raw HTML omitted -->
<p>$$
\begin{align}
\text{Loss of $\delta$ in $D^{(s)}$}: \quad &amp; L[\theta^*, \delta(D^{(s)})] = (\theta^* - \delta(D^{(s)}))^2\\\<br>
\text{Risk of $\delta$ over ${D^{(s)}}_{s=1}^{\infty}$}:\quad &amp;
R(\theta^*, \delta)\\\<br>
\quad &amp;= \mathbb{E}_{D^{(s)}|\theta^*}{L[\theta^*, \delta(D^{(s)})]}\\\<br>
\quad &amp;=\int L[\theta^*, \delta(D^{(s)})] p(D^{(s)}|\theta^*)dD^{(s)}
\end{align}
$$
<!-- raw HTML omitted -->이 Risk를 가장 최소화하는 $\delta$가 가장 Optimal한 추정량이겠지요. 이걸 어떻게 구할 수 있을까요? 못 구해요. 일단 &ldquo;무한 개의 평행우주에서의 데이터&rdquo; 같은 것도 없고, 애초에 참 모수값 $\theta$를 모르니 $p(D^{(s)}\mid\theta)$ 이것도 몰라요. 그래서 빈도통계학에서 &ldquo;최적의 추정량&quot;같은 것은 없습니다. 그렇다고 아예 아무거나 고를 수는 없지요. 그래서 빈도통계론자들은 추정량이 가지면 참 좋을 것 같은 여러 기준을 제시하는데, 무한 데이터 ${D^{(s)}}_{s=1}^{\infty}$에 걸친 추정량 $\delta$의 &ldquo;행태&quot;에 대한 기준이라고 생각해보면 되겠습니다. (때문에 빈도주의보다는 행태주의(Behaviorism)가 더 어울리는 이름이라는 얘기도 있긴 합니다.)</p>
<p><!-- raw HTML omitted -->일단 데이터의 크기가 엄청 늘어나면 추정량이 모수에 근접해야겠지요. 이를 <strong>Consistency</strong>라고 하는데, 가장 기본적인 성질입니다. 상식적으로 생각했을 때 확률실험을 무수히 반복했는데도 모수에 근접하지 않으면 그 추정량은 아무 소용이 없는 것입니다. 이렇게 기본적으로 일치는 해주는 예의를 갖춘 후에 고려할 사항은 <strong>Unbiasedness</strong>와 <strong>Efficiency</strong>입니다. 즉 모든 평행우주 데이터에 걸친 $\delta$의 분포가 가급적이면 모수를 중심으로 하면 좋겠고, 분포의 폭도 좁으면 좋겠다는 것입니다.</p>
<p><!-- raw HTML omitted -->Bias도 없으면서 모든 추정량 중에서 분산도 가장 작으면 좋은 추정량이라고 할 수도 있습니다. 하지만 어느정도 편차가 생겨도 Unbiased한 추정량보다 더 좋을 수도 있습니다. 앞서 우리는 좋은 추정량을 Risk가 작은 추정량으로 이야기했습니다. 이때 squared loss를 가정하면 Risk를 다시 써보면 다음과 같이 쓸 수 있습니다. (squared loss으로 정의된 risk를 Mean Squared Error라고 합니다.) 아마 수통1 시간때 배우셨을 겁니다.</p>
<!-- raw HTML omitted -->
<p>$$
\begin{align}
\mathbb{E}_{D^{(s)}|\theta^*}[\theta^*- \delta(D^{(s)})]^2 &amp;=
\mathbb{E}_{D^{(s)}|\theta^*}(\delta - \mathbb{E}_{D^{(s)}|\theta^*}[\delta])^2 + (\mathbb{E}_{D^{(s)}|\theta^*}[\delta]-\theta^*)^2\\\<br>
&amp;= \mathbb{V}_{D^{(s)}|\theta^*}(\delta) + Bias^2(\delta)\\\<br>
\therefore MSE &amp;= Variance + Bias^2
\end{align}
$$
<!-- raw HTML omitted -->위 식을 보면 추정량을 정할 때 만일 Biased하더라고, 그 편차가 크지 않으면서 줄어든다면 오히려 Unbiased Estimator보다 MSE가 더 적을 수 있음을 알 수 있으며, 나중에 그런 예를 한번 살펴보겠습니다.</p>
<p><!-- raw HTML omitted --> <em>(지금까지 말한 논리는 Supervised Learning에도 그대로 적용됩니다. 어떤 연속형 확률변수 $t$의 값을 예측하는 설명변수들의 함수 $\hat{f}(\mathbf{x})$, 즉 예측 모델을 만드는 문제를 생각해봅시다. 이때 실제 함수는 $f$이겠지만 이를 알 수 없으니 회귀분석 등 갖가지 방법을 이용해 $\hat{f}$를 추정할 수 있습니다. 이 때 $f$와 $\hat{f}$의 관계도 위의 논의와 똑같습니다.)</em></p>
<h2 id="brreferences"><!-- raw HTML omitted -->References</h2>
<ol>
<li>Probability Theory and Statistical Inference: Econometric Modeling with Observational Data (Spanos, 1999)</li>
<li>Machine Learning: a Probabilistic Perspective (Murphy, 2012)</li>
<li>Computer Age Statistical Inference (Efron, Hastie, 2016)</li>
<li>Calibration of p Values for Testing Precise Null Hypotheses (Sellke et al, 2001)</li>
<li><a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf">https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf</a></li>
</ol>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/statistics/" rel="tag">Statistics</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/probability/" rel="tag">Probability</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/frequentist/" rel="tag">Frequentist</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Kang Gyeonghun avatar" src="/mypic1.jpg" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Kang Gyeonghun</span>
	</div>
	<div class="authorbox__description">
		I study statistics, machine learning, data science or whatever that concerns making inference on infinitie dimension from a limited sample in fintie dimension. This blog is an archive of my journey of study.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bayesian-ml/week1/04-frequentist-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%AA%A8%EC%88%98-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">04 Frequentist Approach 하나의 모수, 여러 개의 데이터</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bayesian-ml/week1/06-maximum-likelihood-theory/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">06 Maximum Likelihood Theory</p>
		</a>
	</div>
</nav>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week5/04-note-on-kullback-leibler-divergence/">Note on Kullback-Leibler Divergence</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week5/03-em-algorithm-for-latent-variable-models/">EM Algorithm for Latent Variable Models</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week5/02-mixtures-of-gaussians-and-em/">Mixtures of Gaussians and EM algorithm</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week5/01-k-means-clustering/">K-means clustering</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week3/03-bayesian-hierarchical-modeling-and-applications/">Bayesian Hierarchical Modeling and its Applications</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week3/02-mcmc-approximation-for-bayesian-posterior/">(MCMC) 베이지안 사후분포 근사를 위한 MCMC 방법론</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/adaboost/" title="ADABOOST">ADABOOST</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/adaptive-basis-model/" title="Adaptive Basis Model">Adaptive Basis Model</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayeisan/" title="Bayeisan">Bayeisan</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayesian/" title="Bayesian">Bayesian</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayesian-hierarchical/" title="Bayesian Hierarchical">Bayesian Hierarchical</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bic/" title="BIC">BIC</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bootstrap/" title="Bootstrap">Bootstrap</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cart/" title="CART">CART</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/clustering/" title="Clustering">Clustering</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/conjugacy/" title="Conjugacy">Conjugacy</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/determinant/" title="Determinant">Determinant</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/diagonalization/" title="Diagonalization">Diagonalization</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/em-algorithm/" title="EM algorithm">EM algorithm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ensemble-learning/" title="Ensemble Learning">Ensemble Learning</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/frequentist/" title="Frequentist">Frequentist</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gaussian-mixtures/" title="Gaussian Mixtures">Gaussian Mixtures</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/generalized-additive-models/" title="Generalized Additive Models">Generalized Additive Models</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/intro-to-statistical-learning/" title="Intro to Statistical Learning">Intro to Statistical Learning</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/jacobian/" title="Jacobian">Jacobian</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/k-cv/" title="k-CV">k-CV</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/k-means/" title="K-means">K-means</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/kernel/" title="Kernel">Kernel</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/kullback-leibler-divergence/" title="Kullback-Leibler Divergence">Kullback-Leibler Divergence</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lagrangian-duality/" title="Lagrangian Duality">Lagrangian Duality</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/laplace-approximation/" title="Laplace Approximation">Laplace Approximation</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lasso/" title="Lasso">Lasso</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/latent-variable/" title="Latent Variable">Latent Variable</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lda/" title="LDA">LDA</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/linear-adjoint/" title="Linear Adjoint">Linear Adjoint</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/logistic-regression/" title="Logistic Regression">Logistic Regression</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/markov-chain/" title="Markov Chain">Markov Chain</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/matrix-derivatives/" title="Matrix Derivatives">Matrix Derivatives</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mcmc/" title="MCMC">MCMC</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mse/" title="MSE">MSE</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/multivariate-normal/" title="Multivariate Normal">Multivariate Normal</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/naive-bayes-classifier/" title="Naive Bayes Classifier">Naive Bayes Classifier</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ols/" title="OLS">OLS</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pattern-recognition-and-machine-learning/" title="Pattern Recognition and Machine Learning">Pattern Recognition and Machine Learning</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pca/" title="PCA">PCA</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/probability/" title="Probability">Probability</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/regression-splines/" title="Regression Splines">Regression Splines</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ridge/" title="Ridge">Ridge</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/self-adjoint/" title="Self Adjoint">Self Adjoint</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/similar-matrices/" title="Similar Matrices">Similar Matrices</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/singular-value-decomposition/" title="Singular Value Decomposition">Singular Value Decomposition</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/statistics/" title="Statistics">Statistics</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/svm/" title="SVM">SVM</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/vector-derivatives/" title="vector derivatives">vector derivatives</a>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 Kang Gyeonghun.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>