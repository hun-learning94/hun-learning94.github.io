<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>07 빈도론적 귀무가설유의수준검정(NHST)의 문제점 - Hun Learning</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="Example article description">
		<meta property="og:title" content="07 빈도론적 귀무가설유의수준검정(NHST)의 문제점" />
<meta property="og:description" content="Example article description" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bayesian-ml/week1/07-%EB%B9%88%EB%8F%84%EB%A1%A0%EC%A0%81-%EA%B7%80%EB%AC%B4%EA%B0%80%EC%84%A4%EC%9C%A0%EC%9D%98%EC%88%98%EC%A4%80%EA%B2%80%EC%A0%95nhst%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90/" />
<meta property="article:published_time" content="2020-07-20T05:20:00+09:00" />
<meta property="article:modified_time" content="2020-07-20T05:20:00+09:00" />

		<meta itemprop="name" content="07 빈도론적 귀무가설유의수준검정(NHST)의 문제점">
<meta itemprop="description" content="Example article description">
<meta itemprop="datePublished" content="2020-07-20T05:20:00+09:00" />
<meta itemprop="dateModified" content="2020-07-20T05:20:00+09:00" />
<meta itemprop="wordCount" content="1842">



<meta itemprop="keywords" content="Frequentist," />

	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed">
		<a class="logo__link" href="/" title="Hun Learning" rel="home">
			<div class="logo__item logo__imagebox">
					<img class="logo__img" src="/mypic2.jpg">
				</div><div class="logo__item logo__text">
					<div class="logo__title">Hun Learning</div>
					<div class="logo__tagline">In Search Of The Truth Projected Onto A Finite Dimension</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/posts/about/">
				
				<span class="menu__text">Author</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
	<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
</script>
<script type="text/javascript" async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "all" } }
  });
</script>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">07 빈도론적 귀무가설유의수준검정(NHST)의 문제점</h1>
			<p class="post__lead">숫자 옆에 별표만 잔뜩 치면 다인가?</p>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">Kang Gyeonghun</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2020-07-20T05:20:00&#43;09:00">2020-07-20</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/statistics/" rel="category">Statistics</a>
	</span>
</div></div>
		</header>
		<figure class="post__thumbnail">
			<img src="/cover/classical.jpg" alt="07 빈도론적 귀무가설유의수준검정(NHST)의 문제점">
		</figure><div class="content post__content clearfix">
			<h2 id="br1-빈도론적-추론의-병폐"><!-- raw HTML omitted -->1. 빈도론적 추론의 병폐</h2>
<p>자 이제 빈도통계론의 논리도 이해했고 그 끝판왕인 MLE와 LRT도 봤습니다. 지금부터는 빈도론적 통계 추론, 그 중에서도 검정 (NHST)이 가진 &ldquo;병폐&quot;들에 대해서 살펴보겠습니다. 앞서 잠깐 봤는데, 여기서는 좀 더 자세하게 다뤄보겠습니다.</p>
<h3 id="br1-trigger-happy-pd-mid-h_0만-보고-h_0을-기각함"><!-- raw HTML omitted -->1) Trigger Happy: $p(D \mid H_0)$만 보고 $H_0$을 기각함</h3>
<p>$p(D\mid H_0)$이 굉장히 작아야지만 귀무가설을 기각하는 것이 얼핏 보면 굉장히 보수적으로 보이지만, 사실 이런 식으로 세팅을 해놓으면 &ldquo;귀무가설에 반대되는 evidence&quot;만 반영하게 되지, 귀무가설에 좋은 evidence는 절대 반영을 못함. 실제로 사람들이 관심 있는 것은 $p(H_0\mid D)$에 더 가까움. 그러나 NHST는 이런 거를 반영을 못 함. 이에 대하여 Sellke et al.(2001) 논문은 실제로 p-value가 0.05 미만이지만 $p(H_0\mid D)$는 무려 0.3이 넘는 예시도 제시함. 때문에 귀무가설이 아니다, 즉 어떤 효과가 있다고 결론을 내리기에는 p-value가 굉장히 부적합해서, 어떤 의학 저널에는 p-value만 쓰는거를 금지하기도 했음.</p>
<h3 id="br2-stopping-rule-같은-데이터라도-수집-환경에-따라-결론이-다름"><!-- raw HTML omitted -->2) Stopping Rule: 같은 데이터라도 수집 환경에 따라 결론이 다름</h3>
<p>동전을 던져 앞면이 나온 개수를 세는 실험을 생각해보자.</p>
<ul>
<li>실험 1. 딱 6번 던져서 앞면이 나오는 개수를 센다.</li>
<li>실험 2. 뒷면이 나올 때까지 계속 던지고 난 후 앞면을 셈.</li>
</ul>
<p>두 실험에 의해 똑같은 데이터 HHHHHT가 나왔다고 하자. 상식적으로 p-value는 같아야할 거 같은데, 다르다. 왜 그럴까? 실험 1에서의 귀무가설은 $p=1/2$ 하에서 이항분포이지만, 실험 2에서 귀무가설은 $p=1/2$하에서의 음이항분포이기 때문이다. 때문에 Likelihood가 다르므로 신뢰구간도 다르고, p-value도 다르게 나온다.</p>
<p>이때 실험 1과 2의 차이는 Stopping Rule이다. 실험 1은 미리 수집할 데이터 개수를 정한 경우고, 실험 2는 특정한 기준이 만족 될때까지 (대개 p-value가 이쁘게 나올 때까지) 데이터를 수집하는 경우다. 이러면 실험 1과 실험 2에서 관측된 결과는 같아도 p-value는 다르게 나온다.</p>
<p>때문에 빈도론적 추론을 위해서는 데이터 자체 뿐만 아니라 데이터의 수집 환경까지 고려해야 한다. 이러한 아이러니함을 꼬집은게 바로 <a href="https://psychology.wikia.org/wiki/Likelihood_principle">voltmeter story</a>인데, 결론은 NHST는 Likelihood Principle을 만족하지 않는다는 것. 이 부분은 나도 아직 자세히 이해는 못했지만 충분히 생각해볼 만한 지점인듯.</p>
<h3 id="br3-가설-검정을-많이-하다보면-몇-개가-얻어-걸리게-되어있음"><!-- raw HTML omitted -->3) 가설 검정을 많이 하다보면 몇 개가 얻어 걸리게 되어있음</h3>
<p>유의수준 5%라는게 한번 했을 때 귀무가설을 제대로 기각할 확률이 95%라는거지, 가설검정을 계속 하다보면 귀무가설을 제대로 기각할 확률도 계속 내려가서, 나중에는 거의 무조건 겉으로는 p-value가 유의미하게 나오는 경우가 생김. 이런 문제를 인지하고 가설검정을 에컨대 수 천개 할 때 가설검정 방법으로 제시된게 false-discovery rate인데, 시간이 없어서 아직 공부를 못함</p>
<p><!-- raw HTML omitted --> 여기에 대한 자세한 얘기는 아래에 있습니다.</p>
<h2 id="br2-참고-책으로-훑어보는-고전빈도통계학의-역사"><!-- raw HTML omitted -->2. (참고) 책으로 훑어보는 고전빈도통계학의 역사</h2>
<p><!-- raw HTML omitted --><em>학교 통계학과 커뮤니티에 게재한 글인데, 본 문서와 같이 읽으면 좋을 것 같아 첨부합니다</em></p>
<p><!-- raw HTML omitted -->사실 데이터 분석하려고 통계학을 공부하는 입장에서는 베이지안이나 빈도론 접근을 둘 다 아는게 좋죠! 둘 다 똑같은 가정에서 출발해 가정만 다른건데, 그 차이는 결국 철학과 세계관의 차이로 귀결되고 그 차이를 아는게 적어도 데이터에 대학 확률적 가정을 동반한 데이터 분석에는 큰 도움이 되는 것 같아요. 그리고 대부분의 통계학 교수님들도 뭐 어느쪽으로 기울인 정도는 있겠지만 두 방법 다 알고 계시고 상황에 따라 그때그때 데이터에 더 맞는 접근법을 쓰는 것 같아요. 저도 겉으로는 베이즈 베이즈 하지만 스스로 연구할 준비가 되기 전까지는 앞서간 분들이 닦아놓은 이론들은 가리지 않고 공부하는게 맞다고 생각합니다.</p>
<p><!-- raw HTML omitted -->아무튼!</p>
<p><!-- raw HTML omitted -->그런 점에서 우리가 학교에서 배우는 고전 빈도론 통계학의 맥락을 아는게 좋을 것 같아, 괜찮은 책을 소개하고자 합니다. 이것도 학회 친구들에게 쓴 글인데 좀 다듬고 내용 추가해서 올립니다. 이걸 읽고 나서 수통 2(a.k.a 빈도통계학)를 들으면 더 재밌을 거에요!</p>
<h3 id="br천재들의-주사위-the-lady-tasting-tea-david-salsburg-2001"><!-- raw HTML omitted -->천재들의 주사위 (The lady tasting tea, David Salsburg, 2001)</h3>
<p><!-- raw HTML omitted -->본인이 처음 통방듣고 수통1 들을때 도대체가 수업 내용들이 뭔 맥락이란게 없어서 그 맥락을 찾고 싶어서 책을 뒤지다가 찾은 책인데, 20세기 빈도통계학의 발전과정을 위인전처럼 인물 중심의 서술로 재밌게 엮어낸 책이라, 우리가 배우는 내용에 어떤 역사적인 맥락이 있었는지를 수식같은거 하나도 없이 이야기처럼 재밌게 읽을 수 있는 책이라고 느꼈음. 물론 지금은 읽은지 좀 꽤 돼서 다 까먹었긴 한데, 약간 경제학계에서 &ldquo;세속의 철학자들(by 로버트 하일브로너)&ldquo;라는 책이랑 굉장히 비슷하다고 느꼈음. 칼 피어슨 - 에곤 피어슨 부자와 로날드 피셔의 대를 이으는 자강두천이 하이라이트인거같음. 그리고 피셔께서 흡연과 폐암에 대한 논문들을 &ldquo;Randomize 안 했자나!&ldquo;라며 모조리 까버리며 평생 애연하신게 정말 인상깊었음.</p>
<p><!-- raw HTML omitted -->원래 칼 피어슨이 바이오메트리카 저널 만들면서 먼저 통계학 일짱 먹었는데 (이분은 데이터를 노가다로 계속 모으면서 1,2,3,4차 모멘트를 계산해나가면 결국 당신께서 pearson family라고 부르는 분포함수들 중 하나의 분포를 따를거라고 주장하신거로 본인은 이해함. 그 피아슨패밀리 분포로 퉁치는거를 정당화하는게 카이제곱 피어슨 검정인데, 피어슨 패밀리가 묻히고 피어슨도 학계에서 아싸가 된 후에도 살아남아 당당히 통입책에 등장하는 불멸의 빈도론 검정) 칼 피어슨의 방법론에 정면으로 반기를 든게 피셔라서 처음에 엄청 찍혀서 피셔가 고생했지만 결국 피셔의 너무 우아하고 고귀하고 깔쌈한 방법론에 결국 칼 피어슨이 퇴물됨.</p>
<p><!-- raw HTML omitted -->피셔는 정말 어렸을 때부터 천재였는데 통계학 박사까지 따고도 하필 그때 통계학의 대가인 피어슨 면전에다가 &ldquo;틀렸어요&quot;라고 하니 어디 머리에 피도 안 마른게 덤빈다면서 학계에서 자리가 없어짐. 진짜 공부 많이 하신 어른들이 똥고집은 대단한 듯. 하필 박사 따고 나서 대공황마저 겹쳐서 실업자에 방황하다가 저어어기 한적한 시골동네 농장에서 통계분석하는 자리를 겨우겨우 얻었는데, 거기서 개판으로 모인 데이터와 주먹구구식 일처리를 보고 경악하며 데이터를 모으는 방식과 통계적 추론을 하는 방식을 본인이 처음부터 끝까지 만들었는데 그게 우리가 배우는 통입 통방 실계라고 봐도 과언이 아님. 입지전적인 인물&hellip;</p>
<p><!-- raw HTML omitted -->그 외 피셔의 업적을 잘 모르는 본인이 이해한대로 정리해보자면 크게</p>
<ol>
<li>CLT를 확장해 MLE의 극한분포를 증명함. 물론 그전에도 막연히 최대값 쓰면 되지 않을까~ 싶었지만 그 통계량의 극한에사의 노말리티를 보인 것은 정말 기념비적인 업적. 지금까지도 빈도통계론자들의 No.1 통계량임 그냥 무적권 MLE써야함</li>
<li>귀무가설과 p-value를 처음으로 도입하였으며, 극한분포를 통해 처음으로 &ldquo;통계적 거리&quot;를 나타낼 수 있는 거리함수를 제공함. 통계학자들이 해결해야할 문제들은 대개 데이터만 보면 애매한 것들임. 예컨대 모평균비교를 보면, 박스플럿 그려버면 저놈이 이놈보다 높은거 같은데 애매하네~ 이랬을 때 그 차이가 유의미한지 아닌지, 큰지 작은지를 말해야하는데, 이전에도 그런 시도는 있었지만 처음으로 체계적으로 통계적 거리를 제시한 사람이 피셔라거 생각함. 정확히 말하자면 차이가 없다는 &ldquo;귀무가살&rdquo; 하에서 데이터가 나타내는 이 차이가 얼마나 먼지를 말하는게 바로 귀무가설 하에서의 통계량의 분포이며, 데이터의 값을 넣었을 때 이 귀무가설이 얼마나 말이 안 되는지를 말하는게 p value임.</li>
<li>사견: 피셔의 p-value는 데이터만 보고 모수에 대해 말하겠다는 세계관에서 통계학자가 낼 수 있는 최선임. 그말은 즉 p-value보다 더 한 얘기는 함부로 할 수 없다는 거임. 피셔는 살아생전에 피밸루가 0.05보다 낮으면 귀무가설이 틀린거고 0.050001이면 귀무가설이 맞는거야~ 라는 정신나간 소리는 한번도 할 수 없으며, 오히려 그런 해석을 정말 극도로 경계하거 혐오하며 극렬히 깠음. 피셔에게 피밸류는 그냥 말그대로 &ldquo;evidence against the null hypo&quot;일 뿐임. 피밸류가 높은데 어떡할까요? 라고 물으면 피셔는 데이터 더 모아 ㅂㅅ아 이러고 말았을 인물임. 제한된 데이터를 가지고 &ldquo;기다 아니다&rdquo; 판단하는 것에 대해 극도로 경계하고 주의를 준게 피셔임. 피셔에게 p-value는 오로지 &ldquo;inferential&quot;할 뿐이지, 절대로 어떤 행동방침, 결정알고리즘 이런거를 제공하는 의미가 아님.</li>
</ol>
<p><!-- raw HTML omitted -->그러나 칼 피어슨의 아들인 에곤 피어슨이 네이만과 함께 또 피어슨의 방법론에 반기를 들면서 (정작 아버지는 퇴물이라고 거리둠.. 나중에 피어슨께서는 연구소는 정말 아무도 안 오고 대학교 내에서도 혼자 밥 먹고, 말년이 정말 외로웠을 텐데 아들은 아버지 자존심을 아니까 뭐라 하지는 못하고 피한 것 같음.. 아들아 아빠 연구소 와서 일 도와야지? 앗 아버지 제가 친구랑 논문쓰느라 바빠서^^; 나중에 연락 드릴게요!) 이어지는 드라마를 알고나면 수리통계학 2 공부가 더 재밌을거임. 베이즈 서술은 끝에 약간 반란이라는 식으로 잠깐 서술되고 맘</p>
<p><strong><!-- raw HTML omitted -->첨언:</strong>
<!-- raw HTML omitted -->지금 우리가 통입 통방에서 배우고 사람들이 많이 쓰는 귀무가설유의성검정 (NHST)의 토대를 제공한게 네이만 -(아들) 피어슨 이 두 분임. 이분들은 피셔가 다 만들어놓은 귀무가설 p발루 프레임에다가 어떤 결정알고리즘을 제시하신 분임. 피셔가 귀무가설만 말했다면 네이만 피어슨은 대립가설이란거를 명시적으로 끌고온 분들이며, 진리는 귀무가설 혹은 대립가설에만 있다! 라고 실질적으로 주장하신 거임. 그래서 피셔 철학을 그냥 따로 Fisherian이라고 구분하기도 하는듯.</p>
<p><!-- raw HTML omitted -->쉽게 말하면 피발류가 낮을 때 피셔는
&ldquo;음 귀무가설의 증거가 낮군.&rdquo; 이러고 말았다면 네이만 피어슨은
&ldquo;그러니까 귀무가설이 틀.린.거.이고 대립가설이 맞다!&rdquo; 라고 말할 수 있다는 것을 주장하신 거라고 생각함.</p>
<p><!-- raw HTML omitted -->이렇게 대립가설이란 거를 끌고오니까 이분들은 검정의 power라는거를 제시함. 데이터의 진리는 귀무가설 혹은 대립가설이니, 우리가 진리를 밝히는 검정을 설계할때는 (데이터를 수집해 검정통계량을 만들때에는) 먼저 &ldquo;귀무가설이 맞는데 에쿠 실수로 기각해버리는 알파&rdquo; 확률을 일단 고정하고(&ldquo;유의&quot;수준) 그러고 나서 &ldquo;대립가설이 맞을 때 제대로 결정할 확률&quot;인 검정력, 검정의 파워! 를 최대화해야 한다고 주장하심. 피셔의 검정통계량이 뭐 MLE를 쓰긴 하지만 그건 추정량으로서 착한 통계량이지 검정에 있어서 최선인지 아닌지는 모르고 임의적이었다면, 당신들은 최고의 검정방법과 최고의 검정통계량을 만드는 알고리즘을 제시했다고 의미를 두신 분들이고 수통2 7장부터 우리를 괴롭히시는 분들이지만&hellip; (LRT를 만드신 분들)</p>
<p><!-- raw HTML omitted -->문제는 저 알고리즘이 참 정말 제한적인 상황에서만 &ldquo;uniformly most powerful&quot;하지 대부분의 경우에서는 못 쓴다는거. 정확히 말하면 likelihood가 모노톤하고 (이건 뭐 지수분포족이면 ㅇㅋ한다 쳐도) 단측검정에만 쓸 수 있으니.. 배우긴 배우는데 약간 현실성은 없고 그냥 빈도론자들의 논리는 (이상적인 상황에서는) 고결하다!는 걸 보여주려는 것 같음.</p>
<p><!-- raw HTML omitted -->네이만 피어슨 방식의 이분법은 진짜 진리가 기다 아니다 (방구 꼈냐 안 꼈냐) 이런 상황에서는 정말 좋은데, 모수 공간이 연속적인 경우에서는 대립가설이라는 거 자체가 존나 우스워짐. 무한대와 무한대 사이에서 0이라는 존나 미미한 점 빼고 모두! 라는 가설이 뭔 의미가 있을까?</p>
<p><!-- raw HTML omitted -->또 본인이 생각하기에 네이만 피어슨 논리의 &ldquo;신성모독&quot;은 감히 진리공간을 멋대로 잘라내서 그 안에 정답이 있다고 단언하는 것임. 이게 뭐냐면, 실제 진리공간이 끝없이 넓다면 통계적 추론은 여기서 모수로 결정되는 함수공간을 인위로 그려서 그 안에서만 생각하는 거고, 그게 모수적 가정임. 피셔는 &ldquo;적어도 모수공간의 한 점은 진리일 증거는 희박하다&quot;라고만 말햇는데, 네이만피어슨 논리는 &ldquo;이 점이 아니면 모수공간의 다른 모든 부분 안에 진리가 있다&quot;고 말한것으로, 이는 정말 대담하고 건방진 결론이라고 생각함 본인은.</p>
<p><!-- raw HTML omitted -->네이만은 피셔의 이론을 보고 &ldquo;worse than useless&quot;라고 깠는데, 거기다가 피셔는 이렇게 답했죠.
피셔를 인용하자면,
<strong>&ldquo;네이만 피어슨의 &ldquo;가설검정이론&quot;은 이를 따르는 사람들을 잘못된 길로 이끌어 헛된 노력 끝에 실망을 안겨줄 진데, 정작 그 저자들은 이런 위험을 알려주려고 하지 않는다는 점은 실로 두려운 점이다.</strong>
<strong>It is to be feared, therefore, that the principles of Neyman and Pearson&rsquo;s &ldquo;Theory of Testing Hypothesis&rdquo; are liable to mislead those who follow them into much wasted effort and disappointment, and that its authors are not inclined to warn students of these dangers.(Fisher, 1956)&quot;</strong></p>
<p><!-- raw HTML omitted -->물론 네이만 피어슨 당신들께서는 그렇게까지 생각을 안 하셨을 거고, 그리고 빈도통계학 전공한 통계학자들도 그런 극단적인 사고방식에 동조하지 않을 거임. 그러나 그게 중요한 게 아님. 가장 큰 문제는 적어도 그 논리를 보고 실제 데이터를 다루는 practitioner들이 만들고 교육한 NHST는 암묵적으로 그런 사고를 조장했던게 지금까지의 현실임. 지금 우리가 배우는 NHST는 피셔의 피밸류도 쓰고 네이만피어슨의 검정논리도 쓰는데, 피셔와 네이만 피어슨의 진리공간에 대한 철학의 차이에 대한 사고와 설명 없이 정말 기계적으로 가르쳐지며 숱한 오해를 양산하고 있는게 지금의 현실임.</p>
<p><!-- raw HTML omitted -->본인은 통계학의 사명은 사람들에게 올바른 귀납적 사고 방식의 틀을 제공해주는 것이라고 생각함. 이 점에서 피 밸루에 대한 통계학자들과 통계학을 쓰는 연구자들 간의 크나큰 인식의 괴리와, 그로 인해 생기는 오용과 오해와 그로 인한 일반 대중들의 피해는 빈도통계학자들이 해결해야하는 가장 큰 숙제라고 생각함. 때문에 통계학 써클 이외 대중들에게의 통계학 교육에 실패했다는 것이 옛날부터 나오는 통계학자들의 한탄이었음</p>
<p><!-- raw HTML omitted -->그러니까 빈도통계론자들은 일반 대중에게 NHST라는 &ldquo;쓸 만한&rdquo; 기계를 줬는데, 사용설명서를 아무도 읽어보지 못 하게 써서, 기계를 잘못 써서 손가락 다치거나 중독되는 사람들이 생기는 사태. 이런 사태에서 회사는 당연히 리콜을 해야하는데, 딱히 대체품이 없어서 &ldquo;그&hellip;그렇게 쓰면 안돼여!&rdquo; 라고 말하는 것 외에는 뭐 대안이 없는 것 같음</p>
<p><!-- raw HTML omitted -->여기 나오는 내용에 대해 더 공부하고 싶으면</p>
<ol>
<li>
<p>Probability Theory and Statistical Inference: Econometric Modeling with Observational Data (Spanos, 1999) 이 책의 14장 가설검정 부분
Lady tasting tea 이 책에서 나온 피셔-네이만 논쟁을 내용을 수식을 사용해 설명한다고 보면 됨. 좀 어려워서 수통 1 2 다 듣고 읽어야 읽힐 것임.</p>
</li>
<li>
<p>Fisher, Neyman, and the Creation of Classical Statistics (Lehmann, 2011)
최근에 알게 된 책인데, 저자가 네이만의 제자였다고 합니다. 위의 14장의 내용을 100장으로 풀어낸 책인거같은데 목차만 보고 아직 읽어보지 않음. 시간이 된다면 정말 읽어보고싶은데&hellip; 근데 또 어차피 우리가 수통 2에서 배우는 고전통계학은 사실 모수가 무진장 많은 현대에서는 못써서 읽을 시간이 있을지 모르겠다.</p>
</li>
<li>
<p>Machine Learning: a Probabilistic Perspective (Murphy, 2012) 이 책의 6.6절 pathologies of frequentist statistics 이 부분에서 p-value의 오용 등 빈도적 가설검정의 단점을 신나게 까는데, 머신러닝 전공하신 분이다 보니 빈도통계가 상당히 마음에 들지 않는 모양이심. 여기에 나온 내용의 reference를 공부하면 큰 도움이 될건데, 어려워요&hellip;. 논문들이 진짜 넘 어려워서 안 읽혀요&hellip;.ㅠㅠㅠ</p>
</li>
</ol>
<p><!-- raw HTML omitted -->그 외 구글링에 frequentist vs bayesian compariosn 검색하면 나오는 MIT opencourse 수학과 교수님들이 쓴 10장짜리? 강의노트 너무 좋아요 간단히 요약으로 정리됨 굳굳 그리고 stack exchange나 cross validated 이런 사이트에 열린 스레드 보면 ㄹㅇ 능력자들의 혜안이 담긴 글들이 많아서 보면서 링크 따라가고 참조문헌 공부해보면 이해가 더 깊어질거임!</p>
<h2 id="brreferences"><!-- raw HTML omitted -->References</h2>
<ol>
<li>Probability Theory and Statistical Inference: Econometric Modeling with Observational Data (Spanos, 1999)</li>
<li>Machine Learning: a Probabilistic Perspective (Murphy, 2012)</li>
<li>Computer Age Statistical Inference (Efron, Hastie, 2016)</li>
<li>Calibration of p Values for Testing Precise Null Hypotheses (Sellke et al, 2001)</li>
<li><a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf">https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf</a></li>
</ol>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/frequentist/" rel="tag">Frequentist</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Kang Gyeonghun avatar" src="/mypic1.jpg" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Kang Gyeonghun</span>
	</div>
	<div class="authorbox__description">
		I study statistics, machine learning, data science or whatever that concerns making inference on infinitie dimension from a limited sample in fintie dimension. This blog is an archive of my journey of study.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bayesian-ml/week1/06-maximum-likelihood-theory/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">06 Maximum Likelihood Theory</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bayesian-ml/week1/08-bayesian-approach-%ED%95%98%EB%82%98%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%AC%EB%9F%AC-%EA%B0%9C%EC%9D%98-%EB%AA%A8%EC%88%98/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Bayesian Approach: 하나의 데이터, 임의의 모수</p>
		</a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hun-learning94" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/posts/2020-09-07-intro-to-rcpp-and-rcpparmadillo/">Introduction to Rcpp and RcppArmadillo</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/2020-09-06-how-to-add-rtools-to-windows-path-env/">Rtools를 윈도우 환경변수 PATH에 추가하는 방법</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/2020-08-25-variational-inference/">Variational Inference and Bayesian Gaussian Mixture Model</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/2020-08-24-forward-and-reverse-kl-divergence/">Forward and Reverse KL divergence</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week5/05-mle-minimizes-kl-divergence/">Interpretation of MLE in terms of KL divergence</a></li>
			<li class="widget__item"><a class="widget__link" href="/posts/bayesian-ml/week5/04-note-on-kullback-leibler-divergence/">Note on Kullback-Leibler Divergence</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/adaboost/" title="ADABOOST">ADABOOST</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/adaptive-basis-model/" title="Adaptive Basis Model">Adaptive Basis Model</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayes-rule/" title="Bayes Rule">Bayes Rule</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayesian-gmm/" title="Bayesian GMM">Bayesian GMM</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayesian-hierarchy/" title="Bayesian Hierarchy">Bayesian Hierarchy</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bayesian-networks/" title="Bayesian Networks">Bayesian Networks</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/bootstrap/" title="Bootstrap">Bootstrap</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cart/" title="CART">CART</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/clustering/" title="Clustering">Clustering</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/conjugacy/" title="Conjugacy">Conjugacy</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/d-seperation/" title="D-seperation">D-seperation</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/determinant/" title="Determinant">Determinant</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/diagonalization/" title="Diagonalization">Diagonalization</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/em-algorithm/" title="EM algorithm">EM algorithm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ensemble-learning/" title="Ensemble Learning">Ensemble Learning</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/frequentist/" title="Frequentist">Frequentist</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gaussian-mixtures/" title="Gaussian Mixtures">Gaussian Mixtures</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/generalized-additive-models/" title="Generalized Additive Models">Generalized Additive Models</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gibbs-sampling/" title="Gibbs Sampling">Gibbs Sampling</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/intro-to-statistical-learning/" title="Intro to Statistical Learning">Intro to Statistical Learning</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/jacobian/" title="Jacobian">Jacobian</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/k-cv/" title="k-CV">k-CV</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/k-means/" title="K-means">K-means</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/kernel/" title="Kernel">Kernel</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/kl-divergence/" title="KL divergence">KL divergence</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lagrangian-duality/" title="Lagrangian Duality">Lagrangian Duality</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lasso/" title="Lasso">Lasso</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/latent-variable/" title="Latent Variable">Latent Variable</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lda/" title="LDA">LDA</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/linear-adjoint/" title="Linear Adjoint">Linear Adjoint</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/logistic-regression/" title="Logistic Regression">Logistic Regression</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/markov-chain/" title="Markov Chain">Markov Chain</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/matrix-derivatives/" title="Matrix Derivatives">Matrix Derivatives</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mcmc/" title="MCMC">MCMC</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/metropolis-hastings/" title="Metropolis Hastings">Metropolis Hastings</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mse/" title="MSE">MSE</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/multivariate-normal/" title="Multivariate Normal">Multivariate Normal</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/naive-bayes-classifier/" title="Naive Bayes Classifier">Naive Bayes Classifier</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ols/" title="OLS">OLS</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pca/" title="PCA">PCA</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/posterior-approximation/" title="Posterior Approximation">Posterior Approximation</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/rcpp/" title="Rcpp">Rcpp</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/regression-splines/" title="Regression Splines">Regression Splines</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ridge/" title="Ridge">Ridge</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/self-adjoint/" title="Self Adjoint">Self Adjoint</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/similar-matrices/" title="Similar Matrices">Similar Matrices</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/singular-value-decomposition/" title="Singular Value Decomposition">Singular Value Decomposition</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/stochastic-process/" title="Stochastic Process">Stochastic Process</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/svm/" title="SVM">SVM</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/vector-derivatives/" title="vector derivatives">vector derivatives</a>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 Kang Gyeonghun.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>